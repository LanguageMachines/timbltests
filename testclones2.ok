TiMBL 6.3.4 (c) ILK 1998 - 2011.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Wed Mar  2 14:55:05 2011

Examine datafile './tests/example.train' gave the following results:
Number of Features: 3
InputFormat       : C4.5

Phase 1: Reading Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011
Calculating Entropy         Wed Mar  2 14:55:05 2011
Lines of data     : 29
DB Entropy        : 0.97844933
Number of Classes : 2

Feats	Vals	InfoGain	GainRatio
    1      3	0.21155656	0.16072646
    2      3	0.0060448141	0.0040988196
    3      4	0.044887336	0.023802575

Preparation took 0 seconds, 0 milliseconds and 290 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 2 >
Phase 2: Building multi index on Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Phase 3: Learning from Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Size of InstanceBase = 34 Nodes, (1360 bytes), 29.17 % compression
Learning took 0 seconds, 0 milliseconds and 424 microseconds
Examine datafile './tests/example.test' gave the following results:
Number of Features: 3
InputFormat       : C4.5


Starting to test, Testfile: ./tests/example.test
Writing output in:          testclones.out1
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.160726463858466
Feature 2	 : 0.004098819626097
Feature 3	 : 0.023802575094251

Tested:      1 @ Wed Mar  2 14:55:05 2011
Tested:      2 @ Wed Mar  2 14:55:05 2011
Warning:testfile, skipped line #3
! commentaar
Tested:      3 @ Wed Mar  2 14:55:05 2011
Warning:testfile, skipped line #5
B,fout, raar, rood,a,+
Tested:      4 @ Wed Mar  2 14:55:05 2011
Tested:      5 @ Wed Mar  2 14:55:05 2011
Ready:       5 @ Wed Mar  2 14:55:05 2011
Seconds taken: 0.0006 (8547.01 p/s)

Scores per Value Class:
class  |	TP	FP	TN	FN	precision	recall(TPR)	FPR		F-score		AUC
     + |    	2   	1   	1   	1 	0.66667 	0.66667 	0.50000 	0.66667 	0.58333
     - |    	1   	1   	2   	1 	0.50000 	0.50000 	0.33333 	0.50000 	0.58333
F-Score beta=1, microav: 0.597701
F-Score beta=1, macroav: 0.583333
AUC, microav:            0.583333
AUC, macroav:            0.583333
overall accuracy:        0.600000  (3/5), of which 2 exact matches 

Confusion Matrix:
             +      - 
        --------------
     + |      2      1 
     - |      1      1 
   -*- |      0      0 

TiMBL 6.3.4 (c) ILK 1998 - 2011.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Wed Mar  2 14:55:05 2011

Examine datafile './tests/example.train' gave the following results:
Number of Features: 3
InputFormat       : C4.5

Phase 1: Reading Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011
Calculating Entropy         Wed Mar  2 14:55:05 2011
Lines of data     : 29
DB Entropy        : 0.97844933
Number of Classes : 2

Feats	Vals	InfoGain	GainRatio
    1      3	0.21155656	0.16072646
    2      3	0.0060448141	0.0040988196
    3      4	0.044887336	0.023802575

Preparation took 0 seconds, 0 milliseconds and 266 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 2 >
Phase 2: Building multi index on Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Phase 3: Learning from Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Size of InstanceBase = 34 Nodes, (1360 bytes), 29.17 % compression
Learning took 0 seconds, 0 milliseconds and 398 microseconds
Examine datafile './tests/example.test' gave the following results:
Number of Features: 3
InputFormat       : C4.5


Starting to test, Testfile: ./tests/example.test
Writing output in:          testclones.out3
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.160726463858466
Feature 2	 : 0.004098819626097
Feature 3	 : 0.023802575094251

Tested:      1 @ Wed Mar  2 14:55:05 2011
Tested:      2 @ Wed Mar  2 14:55:05 2011
Warning:testfile, skipped line #3
! commentaar
Warning:testfile, skipped line #5
B,fout, raar, rood,a,+
Tested:      3 @ Wed Mar  2 14:55:05 2011
Tested:      4 @ Wed Mar  2 14:55:05 2011
Tested:      5 @ Wed Mar  2 14:55:05 2011
Ready:       5 @ Wed Mar  2 14:55:05 2011
Seconds taken: 0.0009 (5875.44 p/s)

Scores per Value Class:
class  |	TP	FP	TN	FN	precision	recall(TPR)	FPR		F-score		AUC
     + |    	2   	1   	1   	1 	0.66667 	0.66667 	0.50000 	0.66667 	0.58333
     - |    	1   	1   	2   	1 	0.50000 	0.50000 	0.33333 	0.50000 	0.58333
F-Score beta=1, microav: 0.597701
F-Score beta=1, macroav: 0.583333
AUC, microav:            0.583333
AUC, macroav:            0.583333
overall accuracy:        0.600000  (3/5), of which 2 exact matches 

Confusion Matrix:
             +      - 
        --------------
     + |      2      1 
     - |      1      1 
   -*- |      0      0 

TiMBL 6.3.4 (c) ILK 1998 - 2011.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Wed Mar  2 14:55:05 2011

Examine datafile './tests/example.train' gave the following results:
Number of Features: 3
InputFormat       : C4.5

Phase 1: Reading Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011
Calculating Entropy         Wed Mar  2 14:55:05 2011
Lines of data     : 29
DB Entropy        : 0.97844933
Number of Classes : 2

Feats	Vals	InfoGain	GainRatio
    1      3	0.21155656	0.16072646
    2      3	0.0060448141	0.0040988196
    3      4	0.044887336	0.023802575

Preparation took 0 seconds, 0 milliseconds and 265 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 2 >
Phase 2: Building multi index on Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Phase 3: Learning from Datafile: ./tests/example.train
Start:          0 @ Wed Mar  2 14:55:05 2011
Finished:      29 @ Wed Mar  2 14:55:05 2011

Size of InstanceBase = 34 Nodes, (1360 bytes), 29.17 % compression
Learning took 0 seconds, 0 milliseconds and 393 microseconds
Examine datafile './tests/example.test' gave the following results:
Number of Features: 3
InputFormat       : C4.5


Starting to test, Testfile: ./tests/example.test
Writing output in:          testclones.out7
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.160726463858466
Feature 2	 : 0.004098819626097
Feature 3	 : 0.023802575094251

Warning:testfile, skipped line #3
! commentaar
Tested:      1 @ Wed Mar  2 14:55:05 2011
Tested:      2 @ Wed Mar  2 14:55:05 2011
Tested:      3 @ Wed Mar  2 14:55:05 2011
Tested:      4 @ Wed Mar  2 14:55:05 2011
Warning:testfile, skipped line #5
B,fout, raar, rood,a,+
Tested:      5 @ Wed Mar  2 14:55:05 2011
Ready:       5 @ Wed Mar  2 14:55:05 2011
Seconds taken: 0.0009 (5330.49 p/s)

Scores per Value Class:
class  |	TP	FP	TN	FN	precision	recall(TPR)	FPR		F-score		AUC
     + |    	2   	1   	1   	1 	0.66667 	0.66667 	0.50000 	0.66667 	0.58333
     - |    	1   	1   	2   	1 	0.50000 	0.50000 	0.33333 	0.50000 	0.58333
F-Score beta=1, microav: 0.597701
F-Score beta=1, macroav: 0.583333
AUC, microav:            0.583333
AUC, macroav:            0.583333
overall accuracy:        0.600000  (3/5), of which 2 exact matches 

Confusion Matrix:
             +      - 
        --------------
     + |      2      1 
     - |      1      1 
   -*- |      0      0 

C,rood,3,+,- { + 1.00000, - 2.00000 }        0.0000000000000
C,groen,3,+,+ { + 4.00000, - 3.00000 }        0.0040988196260971
A,groen,-4,-,- { - 4.00000 }        0.027901394720348
B,rood,400,-,+ { + 8.00000, - 4.00000 }        0.023802575094251
C,wit,3,+,+ { + 3.00000, - 1.00000 }        0.0000000000000
