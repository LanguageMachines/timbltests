TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 238 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 181 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.nw.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (18181.82 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        1.0000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        2.0000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        2.0000000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 189 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 178 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.gr.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (18750.00 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.55587713355120
4,5,3,2,3,1,B,B { B 1.00000 }        1.8262346571286
2,4,1,2,3,3,C,C { C 1.00000 }        0.82989467567248
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 191 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 178 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.ig.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (19480.52 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        1.1699250014423
4,5,3,2,3,1,B,B { B 1.00000 }        3.1699250014423
2,4,1,2,3,3,C,C { C 1.00000 }        1.5032583347756
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000
    2      5	9.0000000	0.75000000	1.2516292	0.55587713
    3      2	1.5000000	0.25000000	0.25162917	0.27401754
    4      3	6.0000000	0.50000000	0.91829583	0.73368044
    5      4	12.000000	1.0000000	1.5849625	0.82623466
    6      5	12.000000	1.0000000	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 210 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 180 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.x2.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000000
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000000
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000005

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (19354.84 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        7.5000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        24.000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        10.500000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000
    2      5	9.0000000	0.75000000	1.2516292	0.55587713
    3      2	1.5000000	0.25000000	0.25162917	0.27401754
    4      3	6.0000000	0.50000000	0.91829583	0.73368044
    5      4	12.000000	1.0000000	1.5849625	0.82623466
    6      5	12.000000	1.0000000	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 247 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 239 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.sv.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (18404.91 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 2.00000 }        0.75000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        2.0000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        1.0000000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195
    2      5	12.083046
    3      2	2.5495098
    4      3	6.0553007
    5      4	7.5828754
    6      5	8.9666047

Preparation took 0 seconds, 0 milliseconds and 219 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 181 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.sd.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (19736.84 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        8.6048104649914
4,5,3,2,3,1,B,B { B 1.00000 }        12.681894957644
2,4,1,2,3,3,C,C { C 1.00000 }        14.632555730391
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 302 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 195 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.nw.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (13157.89 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.25000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        0.53333333333333
2,4,1,2,3,3,C,C { C 1.00000 }        1.5000000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 309 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 198 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.gr.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (14423.08 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.13896928338780
4,5,3,2,3,1,B,B { B 1.00000 }        0.47541155237619
2,4,1,2,3,3,C,C { C 1.00000 }        0.55195610889688
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 312 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 200 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.ig.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (13452.91 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.31290729184696
4,5,3,2,3,1,B,B { B 1.00000 }        0.84531333371795
2,4,1,2,3,3,C,C { C 1.00000 }        0.87744375108173
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 331 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 199 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.x2.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (13761.47 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        2.2500000000000
4,5,3,2,3,1,B,B { B 1.00000 }        6.4000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        6.0000000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 328 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 211 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.sv.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (14150.94 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.18750000000000
4,5,3,2,3,1,B,B { B 1.00000 }        0.53333333333333
2,4,1,2,3,3,C,C { C 1.00000 }        0.62500000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 233 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 207 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.sd.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0002 (12765.96 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        3.0207614933986
4,5,3,2,3,1,B,B { B 1.00000 }        3.5474290507357
2,4,1,2,3,3,C,C { C 1.00000 }        8.5910327435937
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 318 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 196 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.nw.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0004 (8130.08 p/s)

overall accuracy:        0.666667  (2/3)
There was 1 tie of which 0 (0.00%) was correctly resolved
0,2,2,3,4,5,A,A { A 1.00000 }        63.000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        65.000000000000
2,4,1,2,3,3,C,A { A 2.00000, B 1.00000 }        46.000000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 312 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 200 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.gr.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0003 (9554.14 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        43.489485740662
4,5,3,2,3,1,B,B { B 1.00000 }        44.959134101868
2,4,1,2,3,3,C,B { B 1.00000 }        31.943479299545
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:04 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010
Calculating Entropy         Mon Aug  9 11:08:04 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 317 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:04 2010
Finished:       6 @ Mon Aug  9 11:08:04 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 219 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.ig.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Mon Aug  9 11:08:04 2010
Tested:      2 @ Mon Aug  9 11:08:04 2010
Tested:      3 @ Mon Aug  9 11:08:04 2010
Ready:       3 @ Mon Aug  9 11:08:04 2010
Seconds taken: 0.0003 (9523.81 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        82.519304275513
4,5,3,2,3,1,B,B { B 1.00000 }        80.022562503815
2,4,1,2,3,3,C,A { A 1.00000 }        60.908275127411
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 335 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 199 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.x2.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0003 (9584.66 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        609.00000000000
4,5,3,2,3,1,B,B { B 1.00000 }        586.50000000000
2,4,1,2,3,3,C,A { A 1.00000 }        448.50000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 336 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 200 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.sv.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0003 (9463.72 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        51.500000000000
4,5,3,2,3,1,B,B { B 1.00000 }        50.000000000000
2,4,1,2,3,3,C,A { A 1.00000 }        37.750000000000
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 229 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 209 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.sd.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0003 (9009.01 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        481.78397583961
4,5,3,2,3,1,B,B { B 1.00000 }        505.68718767166
2,4,1,2,3,3,C,B { B 1.00000 }        396.91791343689
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 333 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 201 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.nw.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4909.98 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99149990081787
4,5,3,2,3,1,B,B { B 1.00000 }        0.98974943161011
2,4,1,2,3,3,C,C { C 1.00000 }        0.94151830673218
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 328 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 198 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.gr.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4950.50 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99325203895569
4,5,3,2,3,1,B,B { B 1.00000 }        0.98577427864075
2,4,1,2,3,3,C,C { C 1.00000 }        0.95932769775391
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 319 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 199 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.ig.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4934.21 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99402451515198
4,5,3,2,3,1,B,B { B 1.00000 }        0.98631763458252
2,4,1,2,3,3,C,C { C 1.00000 }        0.96512484550476
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 335 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 199 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.x2.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4761.90 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99469184875488
4,5,3,2,3,1,B,B { B 1.00000 }        0.98585486412048
2,4,1,2,3,3,C,C { C 1.00000 }        0.97073340415955
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 329 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 213 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.sv.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4870.13 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99381327629089
4,5,3,2,3,1,B,B { B 1.00000 }        0.98625802993774
2,4,1,2,3,3,C,C { C 1.00000 }        0.95734143257141
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 227 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 203 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.sd.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0006 (4622.50 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99274659156799
4,5,3,2,3,1,B,B { B 1.00000 }        0.98764586448669
2,4,1,2,3,3,C,C { C 1.00000 }        0.96492767333984
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 328 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 200 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.nw.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (12987.01 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.43301270189222
4,5,3,2,3,1,B,B { B 1.00000 }        1.3453559924999
2,4,1,2,3,3,C,C { C 1.00000 }        2.5980762113533
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 308 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 197 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.gr.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (13824.88 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.24070185951911
4,5,3,2,3,1,B,B { B 1.00000 }        1.2158389529019
2,4,1,2,3,3,C,C { C 1.00000 }        0.95601602415742
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 314 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 203 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.ig.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (13513.51 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.54197132753771
4,5,3,2,3,1,B,B { B 1.00000 }        2.1323387982329
2,4,1,2,3,3,C,C { C 1.00000 }        1.5197771576574
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 328 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 199 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.x2.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (13824.88 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        3.8971143170300
4,5,3,2,3,1,B,B { B 1.00000 }        16.144271909999
2,4,1,2,3,3,C,C { C 1.00000 }        10.392304845413
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 328 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 214 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.sv.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (13574.66 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.32475952641916
4,5,3,2,3,1,B,B { B 1.00000 }        1.3453559924999
2,4,1,2,3,3,C,C { C 1.00000 }        1.0825317547305
TiMBL 6.3.1 (c) ILK 1998 - 2010.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Aug  9 11:08:05 2010

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010
Calculating Entropy         Mon Aug  9 11:08:05 2010
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 224 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Mon Aug  9 11:08:05 2010
Finished:       6 @ Mon Aug  9 11:08:05 2010

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 222 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.sd.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Mon Aug  9 11:08:05 2010
Tested:      2 @ Mon Aug  9 11:08:05 2010
Tested:      3 @ Mon Aug  9 11:08:05 2010
Ready:       3 @ Mon Aug  9 11:08:05 2010
Seconds taken: 0.0002 (12711.86 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        5.2321123841141
4,5,3,2,3,1,B,B { B 1.00000 }        8.7113533607601
2,4,1,2,3,3,C,C { C 1.00000 }        14.880105201392
