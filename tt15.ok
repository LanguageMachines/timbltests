TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 109 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 123 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.nw.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (36585.37 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        1.0000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        2.0000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        2.0000000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 102 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 83 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.gr.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (41095.89 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.55587713355120
4,5,3,2,3,1,B,B { B 1.00000 }        1.8262346571286
2,4,1,2,3,3,C,C { C 1.00000 }        0.82989467567248
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000
    2      5	1.2516292	0.55587713
    3      2	0.25162917	0.27401754
    4      3	0.91829583	0.73368044
    5      4	1.5849625	0.82623466
    6      5	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 81 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 68 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.ig.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (50847.46 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        1.1699250014423
4,5,3,2,3,1,B,B { B 1.00000 }        3.1699250014423
2,4,1,2,3,3,C,C { C 1.00000 }        1.5032583347756
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000
    2      5	9.0000000	0.75000000	1.2516292	0.55587713
    3      2	1.5000000	0.25000000	0.25162917	0.27401754
    4      3	6.0000000	0.50000000	0.91829583	0.73368044
    5      4	12.000000	1.0000000	1.5849625	0.82623466
    6      5	12.000000	1.0000000	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 201 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 198 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.x2.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000000
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000000
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000005

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (41095.89 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        7.5000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        24.000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        10.500000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000
    2      5	9.0000000	0.75000000	1.2516292	0.55587713
    3      2	1.5000000	0.25000000	0.25162917	0.27401754
    4      3	6.0000000	0.50000000	0.91829583	0.73368044
    5      4	12.000000	1.0000000	1.5849625	0.82623466
    6      5	12.000000	1.0000000	1.5849625	0.70391809

Preparation took 0 seconds, 0 milliseconds and 92 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 61 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.sv.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (55555.56 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 2.00000 }        0.75000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        2.0000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        1.0000000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195
    2      5	12.083046
    3      2	2.5495098
    4      3	6.0553007
    5      4	7.5828754
    6      5	8.9666047

Preparation took 0 seconds, 0 milliseconds and 91 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 68 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.O.sd.k1.out
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (48387.10 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        8.6048104649914
4,5,3,2,3,1,B,B { B 1.00000 }        12.681894957644
2,4,1,2,3,3,C,C { C 1.00000 }        14.632555730391
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 127 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 76 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.nw.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (29411.76 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.25000000000000
4,5,3,2,3,1,B,B { B 1.00000 }        0.53333333333333
2,4,1,2,3,3,C,C { C 1.00000 }        1.5000000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 171 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 107 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.gr.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (22556.39 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.13896928338780
4,5,3,2,3,1,B,B { B 1.00000 }        0.47541155237619
2,4,1,2,3,3,C,C { C 1.00000 }        0.55195610889688
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 112 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 71 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.ig.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (35714.29 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.31290729184696
4,5,3,2,3,1,B,B { B 1.00000 }        0.84531333371795
2,4,1,2,3,3,C,C { C 1.00000 }        0.87744375108173
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 125 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 73 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.x2.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (22556.39 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        2.2500000000000
4,5,3,2,3,1,B,B { B 1.00000 }        6.4000000000000
2,4,1,2,3,3,C,C { C 1.00000 }        6.0000000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 152 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 84 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.sv.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (29702.97 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.18750000000000
4,5,3,2,3,1,B,B { B 1.00000 }        0.53333333333333
2,4,1,2,3,3,C,C { C 1.00000 }        0.62500000000000
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 120 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 91 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.N.sd.k1.out
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (24390.24 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        3.0207614933986
4,5,3,2,3,1,B,B { B 1.00000 }        3.5474290507357
2,4,1,2,3,3,C,C { C 1.00000 }        8.5910327435937
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 163 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 103 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.nw.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0003 (10638.30 p/s)

overall accuracy:        0.666667  (2/3)
There was 1 tie of which 0 (0.00%) was correctly resolved
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999997066334
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999996973202
2,4,1,2,3,3,C,A { A 2.00000, B 1.00000 }        0.99999997857958
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 159 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 101 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.gr.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0002 (13513.51 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999997974863
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999997906427
2,4,1,2,3,3,C,B { B 1.00000 }        0.99999998512516
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 113 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 72 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.ig.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0002 (18987.34 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999996157395
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999996273659
2,4,1,2,3,3,C,A { A 1.00000 }        0.99999997163737
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 127 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 71 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.x2.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0002 (19607.84 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999971641228
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999972688965
2,4,1,2,3,3,C,A { A 1.00000 }        0.99999979115091
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 193 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 110 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.sv.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0003 (11764.71 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999997601844
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999997671694
2,4,1,2,3,3,C,A { A 1.00000 }        0.99999998242129
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 127 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 101 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.D.sd.k1.out
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0002 (13574.66 p/s)

overall accuracy:        0.666667  (2/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.99999977565185
4,5,3,2,3,1,B,B { B 1.00000 }        0.99999976452105
2,4,1,2,3,3,C,B { B 1.00000 }        0.99999981517069
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 120 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 78 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.nw.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0004 (7832.90 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0085000754848845
4,5,3,2,3,1,B,B { B 1.00000 }        0.014699023289897
2,4,1,2,3,3,C,C { C 1.00000 }        0.058481594261305
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 118 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 72 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.gr.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0004 (7894.74 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0067478937392657
4,5,3,2,3,1,B,B { B 1.00000 }        0.018522585078790
2,4,1,2,3,3,C,C { C 1.00000 }        0.038791440543823
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 150 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 90 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.ig.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0005 (6072.87 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0059754460104994
4,5,3,2,3,1,B,B { B 1.00000 }        0.018681172589799
2,4,1,2,3,3,C,C { C 1.00000 }        0.027397577111233
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 158 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 88 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.x2.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0004 (6741.57 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0053082061734488
4,5,3,2,3,1,B,B { B 1.00000 }        0.019261279372034
2,4,1,2,3,3,C,C { C 1.00000 }        0.025149267698088
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 162 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 94 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.sv.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0005 (6172.84 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0061868057406261
4,5,3,2,3,1,B,B { B 1.00000 }        0.018853114652221
2,4,1,2,3,3,C,C { C 1.00000 }        0.034811588366945
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 113 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 93 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.C.sd.k1.out
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0004 (6772.01 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.0072533195868695
4,5,3,2,3,1,B,B { B 1.00000 }        0.012354019376606
2,4,1,2,3,3,C,C { C 1.00000 }        0.033765856224568
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 190 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 94 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.nw.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : No Weighting

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (24390.24 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.43301270189222
4,5,3,2,3,1,B,B { B 1.00000 }        1.3453559924999
2,4,1,2,3,3,C,C { C 1.00000 }        2.5980762113533
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 151 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 91 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.gr.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.555877133551202
Feature 3	 : 0.274017542121281
Feature 4	 : 0.733680436651211
Feature 5	 : 0.826234657128560
Feature 6	 : 0.703918089034135

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (27027.03 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.24070185951911
4,5,3,2,3,1,B,B { B 1.00000 }        1.2158389529019
2,4,1,2,3,3,C,C { C 1.00000 }        0.95601602415742
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      3	1.5849625	1.0000000 NUMERIC
    2      5	1.2516292	0.55587713 NUMERIC
    3      2	0.25162917	0.27401754 NUMERIC
    4      3	0.91829583	0.73368044 NUMERIC
    5      4	1.5849625	0.82623466 NUMERIC
    6      5	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 144 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 89 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.ig.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : InfoGain
Feature 1	 : 1.584962500721156
Feature 2	 : 1.251629167387823
Feature 3	 : 0.251629167387823
Feature 4	 : 0.918295834054489
Feature 5	 : 1.584962500721156
Feature 6	 : 1.584962500721156

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (27027.03 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.54197132753771
4,5,3,2,3,1,B,B { B 1.00000 }        2.1323387982329
2,4,1,2,3,3,C,C { C 1.00000 }        1.5197771576574
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 214 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 124 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.x2.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Chi-square
Feature 1	 : 12.000000000000002
Feature 2	 : 9.000000000000002
Feature 3	 : 1.500000000000000
Feature 4	 : 6.000000000000001
Feature 5	 : 12.000000000000002
Feature 6	 : 12.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0002 (18292.68 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        3.8971143170300
4,5,3,2,3,1,B,B { B 1.00000 }        16.144271909999
2,4,1,2,3,3,C,C { C 1.00000 }        10.392304845413
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	X-square	Variance	InfoGain	GainRatio
    1      3	12.000000	1.0000000	1.5849625	1.0000000 NUMERIC
    2      5	9.0000000	0.75000000	1.2516292	0.55587713 NUMERIC
    3      2	1.5000000	0.25000000	0.25162917	0.27401754 NUMERIC
    4      3	6.0000000	0.50000000	0.91829583	0.73368044 NUMERIC
    5      4	12.000000	1.0000000	1.5849625	0.82623466 NUMERIC
    6      5	12.000000	1.0000000	1.5849625	0.70391809 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 126 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 6, 3, 2 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 36 Nodes, (1440 bytes), 14.29 % compression
Learning took 0 seconds, 0 milliseconds and 76 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.sv.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Shared Variance
Feature 1	 : 1.000000000000000
Feature 2	 : 0.750000000000000
Feature 3	 : 0.250000000000000
Feature 4	 : 0.500000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 1.000000000000000

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (33707.87 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        0.32475952641916
4,5,3,2,3,1,B,B { B 1.00000 }        1.3453559924999
2,4,1,2,3,3,C,C { C 1.00000 }        1.0825317547305
TiMBL 6.5 (c) CLST/ILK/CLIPS 1998 - 2017.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Dec 21 17:40:52 2017

Examine datafile 'tests/numtest.train' gave the following results:
Number of Features: 6
InputFormat       : C4.5

Phase 1: Reading Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017
Calculating Entropy         Thu Dec 21 17:40:52 2017
Lines of data     : 6
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	Standard Deviation
    1      3	5.0990195 NUMERIC
    2      5	12.083046 NUMERIC
    3      2	2.5495098 NUMERIC
    4      3	6.0553007 NUMERIC
    5      4	7.5828754 NUMERIC
    6      5	8.9666047 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 119 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 3, 4, 5, 6 >
Phase 2: Building multi index on Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Phase 3: Learning from Datafile: tests/numtest.train
Start:          0 @ Thu Dec 21 17:40:52 2017
Finished:       6 @ Thu Dec 21 17:40:52 2017

Size of InstanceBase = 39 Nodes, (1560 bytes), 7.14 % compression
Learning took 0 seconds, 0 milliseconds and 92 microseconds
Examine datafile 'tests/numtest.test' gave the following results:
Number of Features: 6
InputFormat       : C4.5


Starting to test, Testfile: tests/numtest.test
Writing output in:          tests/numtest.test.IB1.E.sd.k1.out
Algorithm     : IB1
Global metric : Euclidean Distance
Deviant Feature Metrics:(none)
Weighting     : Standard Deviation
Feature 1	 : 5.099019513592784
Feature 2	 : 12.083045973594572
Feature 3	 : 2.549509756796392
Feature 4	 : 6.055300708194983
Feature 5	 : 7.582875444051551
Feature 6	 : 8.966604708583958

Tested:      1 @ Thu Dec 21 17:40:52 2017
Tested:      2 @ Thu Dec 21 17:40:52 2017
Tested:      3 @ Thu Dec 21 17:40:52 2017
Ready:       3 @ Thu Dec 21 17:40:52 2017
Seconds taken: 0.0001 (25000.00 p/s)

overall accuracy:        1.000000  (3/3)
0,2,2,3,4,5,A,A { A 1.00000 }        5.2321123841141
4,5,3,2,3,1,B,B { B 1.00000 }        8.7113533607601
2,4,1,2,3,3,C,C { C 1.00000 }        14.880105201392
