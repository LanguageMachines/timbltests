TiMBL 6.4.2 (c) ILK 1998 - 2011.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Sep 22 17:10:01 2011

Examine datafile 'tests/hapax.smalltrain' gave the following results:
Number of Features: 14
InputFormat       : Columns

Phase 1: Reading Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:01 2011
Finished:   28405 @ Thu Sep 22 17:10:02 2011
Calculating Entropy         Thu Sep 22 17:10:02 2011
Lines of data     : 28405
DB Entropy        : 9.6917779
Number of Classes : 4947

Feats	Vals	InfoGain	GainRatio
    1   4943	5.3886386	0.55604584
    2   4944	5.4123366	0.55846788
    3   4945	5.4300984	0.56030756
    4   4945	5.5036428	0.56790185
    5   4945	5.5803466	0.57581874
    6   4945	5.6802580	0.58611484
    7   4945	6.0163577	0.62081353
    8   4947	6.0163881	0.62078397
    9   4947	5.6797307	0.58605344
   10   4948	5.5804668	0.57579396
   11   4949	5.5034114	0.56782985
   12   4949	5.4298957	0.56024530
   13   4949	5.4111923	0.55835478
   14   4949	5.3881113	0.55597648

Preparation took 0 seconds, 806 milliseconds and 655 microseconds
Feature Permutation based on GainRatio/Values :
< 7, 8, 6, 9, 5, 10, 4, 11, 3, 12, 2, 13, 1, 14 >
Phase 2: Building multi index on Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:02 2011
Finished:   28405 @ Thu Sep 22 17:10:03 2011

Phase 3: Learning from Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:03 2011
Finished:   28405 @ Thu Sep 22 17:10:04 2011

Size of InstanceBase = 350821 Nodes, (14032840 bytes), 9.55 % compression
Learning took 1 seconds, 327 milliseconds and 760 microseconds
Examine datafile 'tests/hapax.smalltest' gave the following results:
Number of Features: 14
InputFormat       : Columns


Starting to test, Testfile: tests/hapax.smalltest
Writing output in:          testR.out1
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.556045835795306
Feature 2	 : 0.558467880783746
Feature 3	 : 0.560307560110388
Feature 4	 : 0.567901848648317
Feature 5	 : 0.575818740110730
Feature 6	 : 0.586114841881059
Feature 7	 : 0.620813532927729
Feature 8	 : 0.620783965375239
Feature 9	 : 0.586053441066795
Feature 10	 : 0.575793958956889
Feature 11	 : 0.567829845297908
Feature 12	 : 0.560245296566752
Feature 13	 : 0.558354776963652
Feature 14	 : 0.555976477380017

Tested:      1 @ Thu Sep 22 17:10:04 2011
Tested:      2 @ Thu Sep 22 17:10:04 2011
Tested:      3 @ Thu Sep 22 17:10:04 2011
Tested:      4 @ Thu Sep 22 17:10:04 2011
Tested:      5 @ Thu Sep 22 17:10:04 2011
Tested:      6 @ Thu Sep 22 17:10:04 2011
Tested:      7 @ Thu Sep 22 17:10:04 2011
Tested:      8 @ Thu Sep 22 17:10:04 2011
Tested:      9 @ Thu Sep 22 17:10:04 2011
Tested:     10 @ Thu Sep 22 17:10:04 2011
Ready:      86 @ Thu Sep 22 17:10:05 2011
Seconds taken: 1.7054 (50.43 p/s)

overall accuracy:        0.081395  (7/86)
There were 14 ties of which 0 (0.00%) were correctly resolved
TiMBL 6.4.2 (c) ILK 1998 - 2011.
Tilburg Memory Based Learner
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Sep 22 17:10:06 2011

Examine datafile 'tests/hapax.smalltrain' gave the following results:
Number of Features: 14
InputFormat       : Columns

Phase 1: Reading Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:06 2011
Finished:   28405 @ Thu Sep 22 17:10:06 2011
Calculating Entropy         Thu Sep 22 17:10:06 2011
Lines of data     : 28405
DB Entropy        : 9.6917779
Number of Classes : 4947

Feats	Vals	InfoGain	GainRatio
    1   4943	5.3886386	0.55604584
    2   4944	5.4123366	0.55846788
    3   4945	5.4300984	0.56030756
    4   4945	5.5036428	0.56790185
    5   4945	5.5803466	0.57581874
    6   4945	5.6802580	0.58611484
    7   4945	6.0163577	0.62081353
    8   4947	6.0163881	0.62078397
    9   4947	5.6797307	0.58605344
   10   4948	5.5804668	0.57579396
   11   4949	5.5034114	0.56782985
   12   4949	5.4298957	0.56024530
   13   4949	5.4111923	0.55835478
   14   4949	5.3881113	0.55597648

Preparation took 0 seconds, 805 milliseconds and 310 microseconds
Feature Permutation based on GainRatio/Values :
< 7, 8, 6, 9, 5, 10, 4, 11, 3, 12, 2, 13, 1, 14 >
Phase 2: Building multi index on Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:07 2011
Finished:   28405 @ Thu Sep 22 17:10:07 2011

Phase 3: Learning from Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Sep 22 17:10:07 2011
Finished:   28405 @ Thu Sep 22 17:10:08 2011

Size of InstanceBase = 350821 Nodes, (14032840 bytes), 9.55 % compression
Learning took 1 seconds, 337 milliseconds and 572 microseconds
Examine datafile 'tests/hapax.smalltest' gave the following results:
Number of Features: 14
InputFormat       : Columns


Starting to test, Testfile: tests/hapax.smalltest
Writing output in:          testR.out2
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.556045835795306
Feature 2	 : 0.558467880783746
Feature 3	 : 0.560307560110388
Feature 4	 : 0.567901848648317
Feature 5	 : 0.575818740110730
Feature 6	 : 0.586114841881059
Feature 7	 : 0.620813532927729
Feature 8	 : 0.620783965375239
Feature 9	 : 0.586053441066795
Feature 10	 : 0.575793958956889
Feature 11	 : 0.567829845297908
Feature 12	 : 0.560245296566752
Feature 13	 : 0.558354776963652
Feature 14	 : 0.555976477380017

Tested:      1 @ Thu Sep 22 17:10:08 2011
Tested:      2 @ Thu Sep 22 17:10:08 2011
Tested:      3 @ Thu Sep 22 17:10:08 2011
Tested:      4 @ Thu Sep 22 17:10:08 2011
Tested:      5 @ Thu Sep 22 17:10:08 2011
Tested:      6 @ Thu Sep 22 17:10:08 2011
Tested:      7 @ Thu Sep 22 17:10:08 2011
Tested:      8 @ Thu Sep 22 17:10:08 2011
Tested:      9 @ Thu Sep 22 17:10:08 2011
Tested:     10 @ Thu Sep 22 17:10:08 2011
Ready:      86 @ Thu Sep 22 17:10:10 2011
Seconds taken: 1.7121 (50.23 p/s)

overall accuracy:        0.081395  (7/86)
There were 14 ties of which 0 (0.00%) were correctly resolved
