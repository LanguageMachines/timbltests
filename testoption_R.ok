TiMBL 6.4.7 (c) CLST/ILK/CLIPS 1998 - 2016.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Jan 14 09:49:46 2016

Examine datafile 'tests/hapax.smalltrain' gave the following results:
Number of Features: 14
InputFormat       : Columns

Phase 1: Reading Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:46 2016
Finished:   28405 @ Thu Jan 14 09:49:47 2016
Calculating Entropy         Thu Jan 14 09:49:47 2016
Lines of data     : 28405
DB Entropy        : 9.6917779
Number of Classes : 4947

Feats	Vals	InfoGain	GainRatio
    1   4943	5.3886386	0.55604584
    2   4944	5.4123366	0.55846788
    3   4945	5.4300984	0.56030756
    4   4945	5.5036428	0.56790185
    5   4945	5.5803466	0.57581874
    6   4945	5.6802580	0.58611484
    7   4945	6.0163577	0.62081353
    8   4947	6.0163881	0.62078397
    9   4947	5.6797307	0.58605344
   10   4948	5.5804668	0.57579396
   11   4949	5.5034114	0.56782985
   12   4949	5.4298957	0.56024530
   13   4949	5.4111923	0.55835478
   14   4949	5.3881113	0.55597648

Preparation took 0 seconds, 492 milliseconds and 259 microseconds
Feature Permutation based on GainRatio/Values :
< 7, 8, 6, 9, 5, 10, 4, 11, 3, 12, 2, 13, 1, 14 >
Phase 2: Building multi index on Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:47 2016
Finished:   28405 @ Thu Jan 14 09:49:47 2016

Phase 3: Learning from Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:47 2016
Finished:   28405 @ Thu Jan 14 09:49:48 2016

Size of InstanceBase = 350821 Nodes, (14032840 bytes), 9.55 % compression
Learning took 0 seconds, 783 milliseconds and 823 microseconds
Examine datafile 'tests/hapax.smalltest' gave the following results:
Number of Features: 14
InputFormat       : Columns


Starting to test, Testfile: tests/hapax.smalltest
Writing output in:          testR.out1
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.556045835795306
Feature 2	 : 0.558467880783747
Feature 3	 : 0.560307560110388
Feature 4	 : 0.567901848648317
Feature 5	 : 0.575818740110730
Feature 6	 : 0.586114841881059
Feature 7	 : 0.620813532927729
Feature 8	 : 0.620783965375239
Feature 9	 : 0.586053441066795
Feature 10	 : 0.575793958956889
Feature 11	 : 0.567829845297908
Feature 12	 : 0.560245296566752
Feature 13	 : 0.558354776963652
Feature 14	 : 0.555976477380017

Tested:      1 @ Thu Jan 14 09:49:48 2016
Tested:      2 @ Thu Jan 14 09:49:48 2016
Tested:      3 @ Thu Jan 14 09:49:48 2016
Tested:      4 @ Thu Jan 14 09:49:48 2016
Tested:      5 @ Thu Jan 14 09:49:48 2016
Tested:      6 @ Thu Jan 14 09:49:48 2016
Tested:      7 @ Thu Jan 14 09:49:48 2016
Tested:      8 @ Thu Jan 14 09:49:48 2016
Tested:      9 @ Thu Jan 14 09:49:48 2016
Tested:     10 @ Thu Jan 14 09:49:48 2016
Ready:      86 @ Thu Jan 14 09:49:49 2016
Seconds taken: 1.0985 (78.29 p/s)

overall accuracy:        0.081395  (7/86)
There were 14 ties of which 0 (0.00%) were correctly resolved
TiMBL 6.4.7 (c) CLST/ILK/CLIPS 1998 - 2016.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Thu Jan 14 09:49:49 2016

Examine datafile 'tests/hapax.smalltrain' gave the following results:
Number of Features: 14
InputFormat       : Columns

Phase 1: Reading Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:49 2016
Finished:   28405 @ Thu Jan 14 09:49:49 2016
Calculating Entropy         Thu Jan 14 09:49:49 2016
Lines of data     : 28405
DB Entropy        : 9.6917779
Number of Classes : 4947

Feats	Vals	InfoGain	GainRatio
    1   4943	5.3886386	0.55604584
    2   4944	5.4123366	0.55846788
    3   4945	5.4300984	0.56030756
    4   4945	5.5036428	0.56790185
    5   4945	5.5803466	0.57581874
    6   4945	5.6802580	0.58611484
    7   4945	6.0163577	0.62081353
    8   4947	6.0163881	0.62078397
    9   4947	5.6797307	0.58605344
   10   4948	5.5804668	0.57579396
   11   4949	5.5034114	0.56782985
   12   4949	5.4298957	0.56024530
   13   4949	5.4111923	0.55835478
   14   4949	5.3881113	0.55597648

Preparation took 0 seconds, 489 milliseconds and 699 microseconds
Feature Permutation based on GainRatio/Values :
< 7, 8, 6, 9, 5, 10, 4, 11, 3, 12, 2, 13, 1, 14 >
Phase 2: Building multi index on Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:49 2016
Finished:   28405 @ Thu Jan 14 09:49:50 2016

Phase 3: Learning from Datafile: tests/hapax.smalltrain
Start:          0 @ Thu Jan 14 09:49:50 2016
Finished:   28405 @ Thu Jan 14 09:49:50 2016

Size of InstanceBase = 350821 Nodes, (14032840 bytes), 9.55 % compression
Learning took 0 seconds, 778 milliseconds and 407 microseconds
Examine datafile 'tests/hapax.smalltest' gave the following results:
Number of Features: 14
InputFormat       : Columns


Starting to test, Testfile: tests/hapax.smalltest
Writing output in:          testR.out2
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 0.556045835795306
Feature 2	 : 0.558467880783747
Feature 3	 : 0.560307560110388
Feature 4	 : 0.567901848648317
Feature 5	 : 0.575818740110730
Feature 6	 : 0.586114841881059
Feature 7	 : 0.620813532927729
Feature 8	 : 0.620783965375239
Feature 9	 : 0.586053441066795
Feature 10	 : 0.575793958956889
Feature 11	 : 0.567829845297908
Feature 12	 : 0.560245296566752
Feature 13	 : 0.558354776963652
Feature 14	 : 0.555976477380017

Tested:      1 @ Thu Jan 14 09:49:50 2016
Tested:      2 @ Thu Jan 14 09:49:50 2016
Tested:      3 @ Thu Jan 14 09:49:50 2016
Tested:      4 @ Thu Jan 14 09:49:50 2016
Tested:      5 @ Thu Jan 14 09:49:50 2016
Tested:      6 @ Thu Jan 14 09:49:50 2016
Tested:      7 @ Thu Jan 14 09:49:50 2016
Tested:      8 @ Thu Jan 14 09:49:50 2016
Tested:      9 @ Thu Jan 14 09:49:50 2016
Tested:     10 @ Thu Jan 14 09:49:50 2016
Ready:      86 @ Thu Jan 14 09:49:51 2016
Seconds taken: 1.0453 (82.27 p/s)

overall accuracy:        0.081395  (7/86)
There were 14 ties of which 0 (0.00%) were correctly resolved
