TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string.train' gave the following results:
Number of Features: 10
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Warning: datafile, skipped line #3
(1,test2)(4, test4)
Warning: datafile, skipped line #5
( 112913242749723423040, test4) test
Finished:       5 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 3
SkippedLines      : 2
Warning: The following feature(s) have only 1 value: 3, 5, 7, 9-10
DB Entropy        : 1.5849625
Number of Classes : 3

Feats	Vals	InfoGain	GainRatio
    1      2	0.91829583	1.0000000
    2      2	0.91829583	1.0000000
    3      1	0.0000000	0.0000000
    4      2	0.91829583	1.0000000
    5      1	0.0000000	0.0000000
    6      2	0.91829583	1.0000000
    7      1	0.0000000	0.0000000
    8      2	0.91829583	1.0000000
    9      1	0.0000000	0.0000000
   10      1	0.0000000	0.0000000

Preparation took 0 seconds, 0 milliseconds and 255 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 2, 4, 6, 8, 3, 5, 7, 9, 10 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Warning: datafile, skipped line #3
(1,test2)(4, test4)
Warning: datafile, skipped line #5
( 112913242749723423040, test4) test
Finished:       3 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       3 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 32 Nodes, (1280 bytes), 3.03 % compression
Learning took 0 seconds, 0 milliseconds and 179 microseconds
Writing Instance-Base in: sparse.tree
Examine datafile './tests/sparse_string.test' gave the following results:
Number of Features: 10
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string.test
Writing output in:          test.out1
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 1.000000000000000
Feature 3	 : 0.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 0.000000000000000
Feature 6	 : 1.000000000000000
Feature 7	 : 0.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.000000000000000
Feature 10	 : 0.000000000000000

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0001 (22900.76 p/s)

overall accuracy:        0.333333  (1/3), of which 2 exact matches 
(2,test)(7,raar?)klaar,raar { raar 1.00000 }        1.0000000000000
(1,test2)(4,test4)over,over { over 1.00000 }        0.0000000000000
(1,test2)(4,test4)waar,over { over 1.00000 }        0.0000000000000
# Status: complete
# Permutation: < 1, 2, 4, 6, 8, 3, 5, 7, 9, 10 >
# Numeric: .
# Bin_Size: 20
# Version 4 (Hashed)
#
Classes
1	klaar
2	over
3	raar
Features
1	0.0000E-17
2	test
3	test\_3
4	raar?
5	test2
6	test4

(1{ 1 1, 2 1, 3 1 }[1(1[1(3[1(3[1(3[1(3[1(3[1(3[1(3[1(3[1(3{ 3 1 })
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
,2(1[1(1[3(1[4(1[1(1[1(1[1(1[1(1[1(1{ 1 1 })
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
,5(2[1(2[6(2[1(2[1(2[1(2[1(2[1(2[1(2[1(2{ 2 1 })
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
]
)
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Reading Instance-Base from: sparse.tree

Size of InstanceBase = 32 Nodes, (1280 bytes), 3.03 % compression
Feature Permutation based on Data File Ordering :
< 1, 2, 4, 6, 8, 3, 5, 7, 9, 10 >
Examine datafile './tests/sparse_string.test' gave the following results:
Number of Features: 10
InputFormat       : Sparse

Warning: The following feature(s) have only 1 value: 3, 5, 7, 9-10

Starting to test, Testfile: ./tests/sparse_string.test
Writing output in:          test.out2
Algorithm     : IB1
Global metric : Overlap
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 1.000000000000000
Feature 3	 : 0.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 0.000000000000000
Feature 6	 : 1.000000000000000
Feature 7	 : 0.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.000000000000000
Feature 10	 : 0.000000000000000

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0001 (21739.13 p/s)

overall accuracy:        0.333333  (1/3), of which 2 exact matches 
(2,test)(7,raar?)klaar,raar { raar 1.00000 }        1.0000000000000
(1,test2)(4,test4)over,over { over 1.00000 }        0.0000000000000
(1,test2)(4,test4)waar,over { over 1.00000 }        0.0000000000000
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Error:Similarity metric D only accepts -I specifications: -m D:O3
usage:  timbl -f data-file {-t test-file}
or see: timbl -h
        for all possible options

TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Error:Similarity metric C only accepts -I specifications: -m C:O3
usage:  timbl -f data-file {-t test-file}
or see: timbl -h
        for all possible options

TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string_num.train' gave the following results:
Number of Features: 9
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       9 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 8
SkippedLines      : 1
DB Entropy        : 2.5000000
Number of Classes : 6

Feats	Vals	InfoGain	GainRatio
    1      2	0.81127812	1.0000000 NUMERIC
    2      2	0.29356444	0.54007293 NUMERIC
    3 (ignored) 
    4      2	0.81127812	1.0000000 NUMERIC
    5      2	0.81127812	1.0000000 NUMERIC
    6      3	1.0487949	0.80751388 NUMERIC
    7      2	0.81127812	1.0000000 NUMERIC
    8      2	0.81127812	1.0000000 NUMERIC
    9      2	0.29356444	0.54007293 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 329 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 7, 8, 2, 9, 6, 3 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 35 Nodes, (1400 bytes), 22.22 % compression
Learning took 0 seconds, 0 milliseconds and 240 microseconds
Examine datafile './tests/sparse_string_num.test' gave the following results:
Number of Features: 9
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string_num.test
Writing output in:          test.out3
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Ignored features : { 3 } 
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.540072933158727
Feature 3	 : 0.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 0.807513879083834
Feature 7	 : 1.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.540072933158727

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0006 (4709.58 p/s)

overall accuracy:        0.333333  (1/3)
There were 2 ties of which 1 (50.00%) were correctly resolved
(2,3)(7,88)klaar,mies { mies 2.00000 }        0.99999979510903
(1,2)(4,4)over,over { over 1.00000, wim 1.00000 }        0.99999999068677
(1,2)(4,4)waar,over { over 1.00000, wim 1.00000 }        0.99999999068677
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string_num.train' gave the following results:
Number of Features: 9
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       9 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 8
SkippedLines      : 1
DB Entropy        : 2.5000000
Number of Classes : 6

Feats	Vals	InfoGain	GainRatio
    1      2	0.81127812	1.0000000 NUMERIC
    2      2	0.29356444	0.54007293 NUMERIC
    3 (ignored) 
    4      2	0.81127812	1.0000000 NUMERIC
    5      2	0.81127812	1.0000000 NUMERIC
    6      3	1.0487949	0.80751388 NUMERIC
    7      2	0.81127812	1.0000000 NUMERIC
    8      2	0.81127812	1.0000000 NUMERIC
    9      2	0.29356444	0.54007293 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 311 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 4, 5, 7, 8, 2, 9, 6, 3 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 35 Nodes, (1400 bytes), 22.22 % compression
Learning took 0 seconds, 0 milliseconds and 128 microseconds
Examine datafile './tests/sparse_string_num.test' gave the following results:
Number of Features: 9
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string_num.test
Writing output in:          test.out4
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Ignored features : { 3 } 
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.540072933158727
Feature 3	 : 0.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 0.807513879083834
Feature 7	 : 1.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.540072933158727

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0008 (3947.37 p/s)

overall accuracy:        0.333333  (1/3), of which 2 exact matches 
There were 2 ties of which 1 (50.00%) were correctly resolved
(2,3)(7,88)klaar,mies { mies 2.00000 }        0.059242076714429
(1,2)(4,4)over,over { over 1.00000, wim 1.00000 }        0.0000000000000
(1,2)(4,4)waar,over { over 1.00000, wim 1.00000 }        0.0000000000000
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string_num.train' gave the following results:
Number of Features: 9
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       9 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 8
SkippedLines      : 1
DB Entropy        : 2.5000000
Number of Classes : 6

Feats	Vals	InfoGain	GainRatio
    1      2	0.81127812	1.0000000 NUMERIC
    2      2	0.29356444	0.54007293 NUMERIC
    3      2	0.81127812	1.0000000 NUMERIC
    4      2	0.81127812	1.0000000 NUMERIC
    5      2	0.81127812	1.0000000 NUMERIC
    6      3	1.0487949	0.80751388 NUMERIC
    7      2	0.81127812	1.0000000 NUMERIC
    8      2	0.81127812	1.0000000 NUMERIC
    9      2	0.29356444	0.54007293 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 170 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 4, 5, 7, 8, 2, 9, 6 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 39 Nodes, (1560 bytes), 22.00 % compression
Learning took 0 seconds, 0 milliseconds and 121 microseconds
Examine datafile './tests/sparse_string_num.test' gave the following results:
Number of Features: 9
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string_num.test
Writing output in:          test.out5
Algorithm     : IB1
Global metric : Numeric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.540072933158727
Feature 3	 : 1.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 0.807513879083834
Feature 7	 : 1.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.540072933158727

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0001 (23809.52 p/s)

overall accuracy:        0.000000  (0/3), of which 2 exact matches 
There were 2 ties of which 0 (0.00%) were correctly resolved
(2,3)(7,88)klaar,mies { mies 2.00000 }        17.543397285925
(1,2)(4,4)over,mies { over 1.00000, wim 1.00000, mies 2.00000 }        0.0000000000000
(1,2)(4,4)waar,mies { over 1.00000, wim 1.00000, mies 2.00000 }        0.0000000000000
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string_num.train' gave the following results:
Number of Features: 9
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       9 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 8
SkippedLines      : 1
DB Entropy        : 2.5000000
Number of Classes : 6

Feats	Vals	InfoGain	GainRatio
    1      2	0.81127812	1.0000000 NUMERIC
    2      2	0.29356444	0.54007293 NUMERIC
    3      2	0.81127812	1.0000000 NUMERIC
    4      2	0.81127812	1.0000000 NUMERIC
    5      2	0.81127812	1.0000000 NUMERIC
    6      3	1.0487949	0.80751388 NUMERIC
    7      2	0.81127812	1.0000000 NUMERIC
    8      2	0.81127812	1.0000000 NUMERIC
    9      2	0.29356444	0.54007293 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 167 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 4, 5, 7, 8, 2, 9, 6 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 39 Nodes, (1560 bytes), 22.00 % compression
Learning took 0 seconds, 0 milliseconds and 128 microseconds
Examine datafile './tests/sparse_string_num.test' gave the following results:
Number of Features: 9
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string_num.test
Writing output in:          test.out6
Algorithm     : IB1
Global metric : Dot product
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.540072933158727
Feature 3	 : 1.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 0.807513879083834
Feature 7	 : 1.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.540072933158727

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0003 (8928.57 p/s)

overall accuracy:        0.333333  (1/3)
There were 2 ties of which 1 (50.00%) were correctly resolved
(2,3)(7,88)klaar,mies { mies 2.00000 }        0.99999979510903
(1,2)(4,4)over,over { over 1.00000, wim 1.00000 }        0.99999999068677
(1,2)(4,4)waar,over { over 1.00000, wim 1.00000 }        0.99999999068677
TiMBL 6.4.14 (c) CLST/ILK/CLIPS 1998 - 2019.
Tilburg Memory Based Learner
Centre for Language and Speech Technology, Radboud University
Induction of Linguistic Knowledge Research Group, Tilburg University
CLiPS Computational Linguistics Group, University of Antwerp
Mon Sep  2 16:08:54 2019

Examine datafile './tests/sparse_string_num.train' gave the following results:
Number of Features: 9
InputFormat       : Sparse

Phase 1: Reading Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       9 @ Mon Sep  2 16:08:54 2019
Calculating Entropy         Mon Sep  2 16:08:54 2019
Lines of data     : 8
SkippedLines      : 1
DB Entropy        : 2.5000000
Number of Classes : 6

Feats	Vals	InfoGain	GainRatio
    1      2	0.81127812	1.0000000 NUMERIC
    2      2	0.29356444	0.54007293 NUMERIC
    3      2	0.81127812	1.0000000 NUMERIC
    4      2	0.81127812	1.0000000 NUMERIC
    5      2	0.81127812	1.0000000 NUMERIC
    6      3	1.0487949	0.80751388 NUMERIC
    7      2	0.81127812	1.0000000 NUMERIC
    8      2	0.81127812	1.0000000 NUMERIC
    9      2	0.29356444	0.54007293 NUMERIC

Preparation took 0 seconds, 0 milliseconds and 166 microseconds
Feature Permutation based on GainRatio/Values :
< 1, 3, 4, 5, 7, 8, 2, 9, 6 >
Phase 2: Building multi index on Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Phase 3: Learning from Datafile: ./tests/sparse_string_num.train
Start:          0 @ Mon Sep  2 16:08:54 2019
Finished:       8 @ Mon Sep  2 16:08:54 2019

Size of InstanceBase = 39 Nodes, (1560 bytes), 22.00 % compression
Learning took 0 seconds, 0 milliseconds and 121 microseconds
Examine datafile './tests/sparse_string_num.test' gave the following results:
Number of Features: 9
InputFormat       : Sparse


Starting to test, Testfile: ./tests/sparse_string_num.test
Writing output in:          test.out7
Algorithm     : IB1
Global metric : Cosine metric
Deviant Feature Metrics:(none)
Weighting     : GainRatio
Feature 1	 : 1.000000000000000
Feature 2	 : 0.540072933158727
Feature 3	 : 1.000000000000000
Feature 4	 : 1.000000000000000
Feature 5	 : 1.000000000000000
Feature 6	 : 0.807513879083834
Feature 7	 : 1.000000000000000
Feature 8	 : 1.000000000000000
Feature 9	 : 0.540072933158727

Tested:      1 @ Mon Sep  2 16:08:54 2019
Tested:      2 @ Mon Sep  2 16:08:54 2019
Tested:      3 @ Mon Sep  2 16:08:54 2019
Ready:       3 @ Mon Sep  2 16:08:54 2019
Seconds taken: 0.0012 (2500.00 p/s)

overall accuracy:        0.333333  (1/3), of which 2 exact matches 
There were 2 ties of which 1 (50.00%) were correctly resolved
(2,3)(7,88)klaar,mies { mies 2.00000 }        0.059242076714429
(1,2)(4,4)over,over { over 1.00000, wim 1.00000 }        0.0000000000000
(1,2)(4,4)waar,over { over 1.00000, wim 1.00000 }        0.0000000000000
